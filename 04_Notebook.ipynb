{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7901fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install linearmodels\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from linearmodels.panel import PanelOLS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & FEATURE ENGINEERING\n",
    "# ==========================================\n",
    "# UPDATE!!!: Local Directory Paths\n",
    "print(\">> PHASE 4: INITIALIZING DATA...\")\n",
    "\n",
    "# CONFIGURATION\n",
    "DATA_DIR = r'data/raw'\n",
    "OUTPUT_DIR = r'data/processed'\n",
    "IMG_DIR = r'data/visuals'\n",
    "\n",
    "for d in [OUTPUT_DIR, IMG_DIR]:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "\n",
    "# Load Artifacts\n",
    "df_raw = pd.read_csv(os.path.join(OUTPUT_DIR, 'ERI_Phase2_Track1_Model.csv'))\n",
    "df_eri = pd.read_csv(os.path.join(OUTPUT_DIR, 'ERI_Phase3_Analytical_Base.csv'))\n",
    "df_meta = pd.read_csv(os.path.join(OUTPUT_DIR, 'ERI_Phase3_Sector_Archetypes.csv'))\n",
    "\n",
    "# --- CRITICAL FIX 1: FORCE COLUMN RENAMING ---\n",
    "# Ensure the column is named 'Archetype'\n",
    "if 'Archetype' not in df_meta.columns:\n",
    "    candidates = ['Resilience_Archetype', 'resilience_archetype', 'archetype', 'Archetypes']\n",
    "    for c in candidates:\n",
    "        if c in df_meta.columns:\n",
    "            df_meta.rename(columns={c: 'Archetype'}, inplace=True)\n",
    "            break\n",
    "    if 'Archetype' not in df_meta.columns:\n",
    "        df_meta.rename(columns={df_meta.columns[-1]: 'Archetype'}, inplace=True)\n",
    "\n",
    "# --- CRITICAL FIX 2: TRANSLATE LABELS ---\n",
    "# Map the \"Technical\" names to the \"User Preferred\" names\n",
    "label_map = {\n",
    "    'Stalwart (High Res, Low Vol)': 'All-Weather Star\\n(High Res, Low Vol)',\n",
    "    'Cyclical Grower (High Res, High Vol)': 'Volatile Grower\\n(High Res, High Vol)',\n",
    "    'Stagnant (Low Res, Low Vol)': 'Safe Stagnator\\n(Low Res, Low Vol)',\n",
    "    'Distressed (Low Res, High Vol)': 'Distressed\\n(Low Res, High Vol)'\n",
    "}\n",
    "\n",
    "# Apply mapping (If the key isn't found, it keeps the original value)\n",
    "df_meta['Archetype'] = df_meta['Archetype'].map(lambda x: label_map.get(x, x))\n",
    "df_meta['Archetype'] = df_meta['Archetype'].fillna('Distressed\\n(Low Res, High Vol)')\n",
    "\n",
    "# --- A. Construct Labor Productivity Proxy ---\n",
    "file_gdp = 'gdp_current_prices_by_industry.csv'\n",
    "file_emp = 'DOS_Employment_Change_By_Sector_Quarterly.csv'\n",
    "\n",
    "df_gdp = df_raw[df_raw['source_file'] == file_gdp][['date', 'clean_sector', 'value']].rename(columns={'value': 'GDP_Nominal'})\n",
    "df_emp = df_raw[df_raw['source_file'] == file_emp][['date', 'clean_sector', 'value']].rename(columns={'value': 'Emp_Change'})\n",
    "\n",
    "if df_gdp.empty or df_emp.empty:\n",
    "    print(\"⚠️ WARNING: Data extraction failed. Check source_file names.\")\n",
    "\n",
    "df_proxy = pd.merge(df_gdp, df_emp, on=['date', 'clean_sector'], how='inner')\n",
    "df_proxy.sort_values(by=['clean_sector', 'date'], inplace=True)\n",
    "\n",
    "if not df_proxy.empty:\n",
    "    # Robust productivity calculation\n",
    "    df_proxy['Emp_Index'] = df_proxy.groupby('clean_sector')['Emp_Change'].transform(lambda x: x.cumsum() - x.cumsum().min() + 100)\n",
    "    df_proxy['Labor_Productivity'] = df_proxy['GDP_Nominal'] / df_proxy['Emp_Index']\n",
    "\n",
    "# --- B. The Master Merge ---\n",
    "df_proxy.rename(columns={'clean_sector': 'mapped_sector'}, inplace=True)\n",
    "df_proxy['date'] = pd.to_datetime(df_proxy['date'])\n",
    "df_eri['date'] = pd.to_datetime(df_eri['date'])\n",
    "\n",
    "df_model = pd.merge(df_eri, df_proxy[['mapped_sector', 'date', 'Labor_Productivity']], on=['mapped_sector', 'date'], how='inner')\n",
    "\n",
    "if 'Archetype' not in df_model.columns:\n",
    "    df_model = pd.merge(df_model, df_meta[['mapped_sector', 'Archetype']], on='mapped_sector', how='left')\n",
    "\n",
    "# --- C. Advanced Features ---\n",
    "df_model.sort_values(by=['mapped_sector', 'date'], inplace=True)\n",
    "df_model['Prod_Lag2Y'] = df_model.groupby('mapped_sector')['Labor_Productivity'].shift(8)\n",
    "df_model['Prod_Centered'] = df_model['Labor_Productivity'] - df_model['Labor_Productivity'].mean()\n",
    "df_model['Prod_Squared'] = df_model['Prod_Centered'] ** 2\n",
    "# Ensure fillna uses the new label format\n",
    "df_model['Archetype'] = df_model['Archetype'].fillna('Distressed\\n(Low Res, High Vol)')\n",
    "\n",
    "print(f\">> Master Dataset Ready. Shape: {df_model.shape}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. STATISTICAL INFERENCE (THE \"WHY\")\n",
    "# ==========================================\n",
    "print(\"\\n>> RUNNING STATISTICAL INFERENCE...\")\n",
    "\n",
    "if not df_model.empty:\n",
    "    df_panel = df_model.set_index(['mapped_sector', 'date'])\n",
    "    try:\n",
    "        mod_fe = PanelOLS.from_formula('ERI_Score_V1 ~ Labor_Productivity + EntityEffects', data=df_panel)\n",
    "        res_fe = mod_fe.fit(cov_type='clustered', cluster_entity=True)\n",
    "        print(\"--- PANEL FIXED EFFECTS (V1) ---\")\n",
    "        print(res_fe.summary.tables[1])\n",
    "    except:\n",
    "        print(\"⚠️ PanelOLS Failed.\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. MACHINE LEARNING TOURNAMENT (THE \"HOW\")\n",
    "# ==========================================\n",
    "def run_tournament(target_col, data_df):\n",
    "    print(f\"\\n>> RUNNING TOURNAMENT FOR TARGET: {target_col}\")\n",
    "\n",
    "    # Deterministic Sort\n",
    "    df_clean = data_df.dropna(subset=[target_col, 'Labor_Productivity', 'Archetype']).sort_values(by=['mapped_sector', 'date'])\n",
    "    \n",
    "    if df_clean.empty: return None, \"None\", 0.0\n",
    "\n",
    "    X = df_clean[['Labor_Productivity', 'Archetype']]\n",
    "    y = df_clean[target_col]\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), ['Labor_Productivity']),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), ['Archetype'])\n",
    "    ])\n",
    "\n",
    "    models = {\n",
    "        'Ridge (Linear)': Pipeline([('prep', preprocessor), ('reg', Ridge())]),\n",
    "        'Poly (Deg 2)': Pipeline([('prep', preprocessor), ('poly', PolynomialFeatures(2)), ('reg', LinearRegression())]),\n",
    "        'Random Forest': Pipeline([('prep', preprocessor), ('reg', RandomForestRegressor(n_estimators=200, random_state=42))]),\n",
    "        'Gradient Boosting': Pipeline([('prep', preprocessor), ('reg', GradientBoostingRegressor(n_estimators=200, random_state=42))])\n",
    "    }\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    results = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        try:\n",
    "            model.fit(X_train, y_train)\n",
    "            score = model.score(X_test, y_test)\n",
    "            results.append({'Model': name, 'R2': score})\n",
    "        except:\n",
    "            results.append({'Model': name, 'R2': -np.inf})\n",
    "\n",
    "    df_res = pd.DataFrame(results).sort_values('R2', ascending=False)\n",
    "    print(df_res)\n",
    "    best_row = df_res.iloc[0]\n",
    "    return models[best_row['Model']], best_row['Model'], best_row['R2']\n",
    "\n",
    "champ_v1, name_v1, score_v1 = run_tournament('ERI_Score_V1', df_model)\n",
    "champ_v2, name_v2, score_v2 = run_tournament('ERI_Score_V2', df_model)\n",
    "\n",
    "# ==========================================\n",
    "# 4. STRUCTURAL AUDIT (PCA & LAGS)\n",
    "# ==========================================\n",
    "print(\"\\n>> RUNNING TWIN TEST (Lags & Limits)...\")\n",
    "twin_res = []\n",
    "df_twin = df_model.dropna(subset=['Prod_Lag2Y', 'Prod_Squared'])\n",
    "\n",
    "if not df_twin.empty:\n",
    "    for target in ['ERI_Score_V1', 'ERI_Score_V2']:\n",
    "        try:\n",
    "            mod_lag = smf.ols(f\"{target} ~ Prod_Lag2Y + C(Archetype)\", data=df_twin).fit()\n",
    "            is_j_curve = \"YES\" if (mod_lag.params['Prod_Lag2Y'] > 0 and mod_lag.pvalues['Prod_Lag2Y'] < 0.05) else \"NO\"\n",
    "\n",
    "            mod_quad = smf.ols(f\"{target} ~ Prod_Centered + Prod_Squared + C(Archetype)\", data=df_twin).fit()\n",
    "            is_limit = \"YES\" if (mod_quad.params['Prod_Squared'] < 0 and mod_quad.pvalues['Prod_Squared'] < 0.05) else \"NO\"\n",
    "\n",
    "            twin_res.append({'Index': target, 'J-Curve (Lag)': is_j_curve, 'Eff Limit (Quad)': is_limit})\n",
    "        except:\n",
    "            twin_res.append({'Index': target, 'J-Curve (Lag)': 'ERR', 'Eff Limit (Quad)': 'ERR'})\n",
    "\n",
    "    df_twin_res = pd.DataFrame(twin_res)\n",
    "    print(df_twin_res)\n",
    "else:\n",
    "    print(\"⚠️ Skipping Twin Test: Not enough data.\")\n",
    "    df_twin_res = pd.DataFrame()\n",
    "\n",
    "# ==========================================\n",
    "# 5. FORECASTING (2026: SIDE-BY-SIDE)\n",
    "# ==========================================\n",
    "print(\"\\n>> RUNNING 2026 STRESS TEST (V1 vs V2)...\")\n",
    "\n",
    "if champ_v1 and champ_v2 and not df_model.empty:\n",
    "    latest_data = df_model.sort_values('date').groupby('mapped_sector').tail(1).copy()\n",
    "    scenarios = {'Shock (-10%)': 0.90, 'Baseline': 1.00, 'Boom (+10%)': 1.10}\n",
    "\n",
    "    sim_results = []\n",
    "    for sc_name, multiplier in scenarios.items():\n",
    "        sim_df = latest_data.copy()\n",
    "        sim_df['Labor_Productivity'] *= multiplier\n",
    "        sim_df['Pred_V1'] = champ_v1.predict(sim_df[['Labor_Productivity', 'Archetype']])\n",
    "        sim_df['Pred_V2'] = champ_v2.predict(sim_df[['Labor_Productivity', 'Archetype']])\n",
    "        agg = sim_df.groupby('Archetype')[['Pred_V1', 'Pred_V2']].mean().reset_index()\n",
    "        agg['Scenario'] = sc_name\n",
    "        sim_results.append(agg)\n",
    "\n",
    "    if sim_results:\n",
    "        df_sim = pd.concat(sim_results)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, 7), sharey=True)\n",
    "        \n",
    "        # We manually update ticks to avoid UserWarning\n",
    "        def set_labels(ax):\n",
    "            ticks = ax.get_xticks()\n",
    "            labels = ax.get_xticklabels()\n",
    "            # If labels are empty (sometimes happens before drawing), we skip wrapping\n",
    "            if len(labels) > 0:\n",
    "                ax.set_xticks(ticks) # Fix ticks\n",
    "                ax.set_xticklabels(labels, rotation=0)\n",
    "\n",
    "        # Plot V1\n",
    "        sns.barplot(\n",
    "            data=df_sim, x='Archetype', y='Pred_V1', hue='Scenario',\n",
    "            palette={'Shock (-10%)': '#d62728', 'Baseline': 'gray', 'Boom (+10%)': '#1f77b4'},\n",
    "            ax=axes[0]\n",
    "        )\n",
    "        axes[0].set_title(f'V1 Forecast: Policy View\\n(Sensitive)\\nChampion: {name_v1}', fontsize=12)\n",
    "        axes[0].set_ylabel('Projected Resilience Score')\n",
    "        axes[0].set_ylim(0.4, 0.85)\n",
    "        axes[0].grid(axis='y', linestyle='--', alpha=0.3)\n",
    "        if axes[0].get_legend(): axes[0].get_legend().remove()\n",
    "        set_labels(axes[0])\n",
    "\n",
    "        # Plot V2\n",
    "        sns.barplot(\n",
    "            data=df_sim, x='Archetype', y='Pred_V2', hue='Scenario',\n",
    "            palette={'Shock (-10%)': '#d62728', 'Baseline': 'gray', 'Boom (+10%)': '#1f77b4'},\n",
    "            ax=axes[1]\n",
    "        )\n",
    "        axes[1].set_title(f'V2 Forecast: Robust View\\n(Stable/Stubborn)\\nChampion: {name_v2}', fontsize=12)\n",
    "        axes[1].set_xlabel('Sector Archetype')\n",
    "        axes[1].grid(axis='y', linestyle='--', alpha=0.3)\n",
    "        axes[1].legend(title='2026 Scenario', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "        set_labels(axes[1])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(IMG_DIR, '10_Forecast_Comparison_2026.png'), dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "        # Grand Comparison Table\n",
    "        print(\"\\n>> SAVING GRAND COMPARISON...\")\n",
    "        v1_lag = df_twin_res.iloc[0]['J-Curve (Lag)'] if not df_twin_res.empty else \"N/A\"\n",
    "        v2_lag = df_twin_res.iloc[1]['J-Curve (Lag)'] if not df_twin_res.empty else \"N/A\"\n",
    "        \n",
    "        grand_comp = pd.DataFrame({\n",
    "            'Metric': ['Champion Model', 'Fit (R2)', 'Lag Effect'],\n",
    "            'V1 (Policy)': [name_v1, f\"{score_v1:.2f}\", v1_lag],\n",
    "            'V2 (Robust)': [name_v2, f\"{score_v2:.2f}\", v2_lag]\n",
    "        })\n",
    "        grand_comp.to_csv(os.path.join(OUTPUT_DIR, 'ERI_Phase4_Grand_Comparison.csv'), index=False)\n",
    "        print(grand_comp)\n",
    "\n",
    "print(\"\\n>> PHASE 4 COMPLETE.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
